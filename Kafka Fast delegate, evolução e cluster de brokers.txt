***AULA01
O processo de serialização e desserialização só usa os campos, não importa se a classe Order de fraud ppossui mais métodos que a classe Order do new-order
** O LogService só pega os tópicos depois que foram criados, se forem criados durante o processo em que ele já estiver rodando, os mesmos não serão detectados. 
É preciso derrubar os serviços e rodar novamente.

O que aprendemos nessa aula:

Como fazer um consumidor também produzir
Como lidar com patterns e novos topics
Como acessar um banco de dados
Problemas de schema que vão sendo levantados durante a evolução dos serviços

***AULA02

A key pelo usuário garantia que: se um usuário fizesse duas compras, será processada a primeira compra e depois a segunda, ou seja, os pedidos são processados na ordem pela chave do usuário. 
Para a mesma chave é executado sequencialmente. Se o usuário faz três compras, a tentativa de processamento é na 1 depois na 2 e por ultimo na 3.
Objetivo é garantir que todas as compras de um mesmo usuário venham em ordem.
Para a mesma chave a execução é sequencial.
Chaves distintas torna o processo paralelo.

O que aprendemos nessa aula:

como evoluir um serviço sem quebrar os schemas
como pensar a evolução de um serviço
discutindo UUID e id único

***AULA03
Servidor http como ponto de entrada

Quanto menos código no servidor http melhor, mais rápido de mandar a mensagem para o broker e termos um "log do que aconteceu". 
Fazendo o tratamento dessa forma temos menas chance de acontecer algum erro e perdermos a mensagem.

O que aprendemos nessa aula:

como usar um servidor http embarcado
como criar um serviço http
como enviar mensagens a partir do servidor http
a vantagem de um fast delegate

***AULA04
O número de consumidores deve ser menor ou igual ao numero de partições para paralelizarmos.
Na atual configuração se um dos consumidores cair, o outro assume a partição.

**> Configurando mais de um broker (na mesma máquina):
Alterando o id do broker 2, após copiar o arquivo server.properties. Utilizamos o id 2 para facilitar a identificação.
# The id of the broker. This must be set to a unique integer for each broker.
broker.id=2

Tem que mudar o diretório dos log:
# A comma separated list of directories under which to store log files
log.dirs=

Como é na mesma máquina, é necessário alterar a porta, o ideal seria rodar o kafka em duas ou mais máquinas distintas.
listeners=PLAINTEXT://:9093

Não é possivel alterar o via comando de alteração do topico a quantidade de replicas, só no momento da criação do topico é possivel definir.

-Incluir a propriedade 
default.replication.factor=2

no server.properties e no server2.properties

derrubar zookepeer, kafka e apagar filas do diretorio

star no zookepeer e nos dois server kafka.

isr-> indica quantas replicas estão atualizadas
leader none -> em alguns casos alguns dados podem ficar sem replicas, somente quando o server que caiu sobre é que esse dados do respectivo consumidor é destravado.
Como o kafka asmazena a ultima mensagem lida em um tópico, se esse kafka broker cair, essa informação é perdida pq o replication factory é 1.

**> Evitando o ponto de falha no broker com os metadados internos dos tópicos
Abrir o server.properties e chegar neste ponto:

############################# Internal Topic Settings  #############################
# The replication factor for the group metadata internal topics "__consumer_offsets" and "__transaction_state"
# For anything other than development testing, a value greater than 1 is recommended to ensure availability such as 3.
offsets.topic.replication.factor=3
transaction.state.log.replication.factor=3
transaction.state.log.min.isr=3

Como é alertado no próprio comentário, esse valor deve ser maior do que 1 e o valor geralmente utilizado é 3
É interessante também configurar o default.replication.factor de 2 para 3

no curso criamos configuração para 5 brokers na mesma maquina alterando as portas.

**>configurando em duas máquinas distintas
https://kafka.apache.org/quickstart#quickstart_multibroker

ISR => in sync replicas

**> configurações de recebimento de mensagem
Situações:

Lider recebe mas não atualiza as replicas (replicas off line)
Lider recebe, cai, e as replicas estão desatualizadas
Lider receber e se replicou ou não, tanto faz, normal perder uma ou outra mensagem

No curso e na maioria dos casos é comum a configuração ALL, só é ACK quando a mensagem for replicada para os WB replicas (slaves). Estamos garantindo que em pelo menos mais dois lugares teremos cópia d amensagem.

O ALL espera uma replica que está sincronizada responser, respondendo, tudo ok.
Se eu tenho N replicas, só terei a garantia das N replicas se meu ACKs for ALL, se meu ACKs for 1, eu tenho as N replicas, mas corro o risco de receber a uma confirmação que somente uma delas ficou sabendo.
Mesmo no ACKs all pode acontecer, pq pode chegar ao ponto de ter apenas uma maquina rodando e as restantes estão offline.

A ideia é trabalhar com número de partições, replicações e ACK all para garantir que os dados estejam em algum lugar.
"Trabalhar com o número de partições, número de réplicas e acks all para o máximo de reliability de segurança de que os dados estão em algum lugar e serão consumidos."

O que aprendemos nessa aula:

o problema do single point of failure
a recuperação mais simples de um broker
a recuperação e o rebalanceamento de um serviço
como levantar mais um broker e rodar um cluster
como efetuar a replicação
o que é um líder
a configuração do acks 0, 1 e all
como utilizar garantias, reliability, velocidade, partições e replicação



